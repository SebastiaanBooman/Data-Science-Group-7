{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Vector Auto-Regressive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes sure Pandas keeps it mouth shut\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "warnings.simplefilter(action = 'ignore', category = RuntimeWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Before we do anything, we first import our unmodified dataset and introduce some new useful columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = 'gdp_growth'\n",
    "dep_name = 'GDP Growth'\n",
    "gdp_type = 'rgdpna'\n",
    "country_codes = ['DEU', 'USA']\n",
    "features = ['emp', 'avh', 'rtfpna', 'rdana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwt = pd.read_excel('../../../Data/pwt1001.xlsx',\n",
    "                    sheet_name = 'Data',\n",
    "                    parse_dates = ['year'],\n",
    "                    index_col = 3)\n",
    "\n",
    "# Create a new column for GDP Growth\n",
    "pwt[f'{gdp_type}_lag'] = pwt.groupby(['countrycode'])[gdp_type].shift(1)\n",
    "pwt['gdp_growth'] = pwt.apply(lambda row : ((row[gdp_type] - row[f'{gdp_type}_lag']) / row[f'{gdp_type}_lag']) * 100, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we:\n",
    "- Filter out the countries we will make the predictions for\n",
    "- Select the columns we use in the calculation\n",
    "- Drop N/A values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_countries(data: pd.DataFrame, countries: list[str]) -> bool:\n",
    "    result = {}\n",
    "\n",
    "    # Filter out the relevant countries\n",
    "    data = data[data['countrycode'].isin(countries)]\n",
    "\n",
    "    # Filter out the variables we need and drop N/A values\n",
    "    data = data[['country', 'countrycode', dep] + features]\n",
    "    data = data.dropna()\n",
    "\n",
    "    for countrycode, name in zip(countries, data['country'].unique()):\n",
    "        result[name] = {}\n",
    "        result[name]['raw'] = data[data['countrycode'] == countrycode].drop(['country', 'countrycode'], axis = 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "countries = extract_countries(pwt, country_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "#print([variance_inflation_factor(df.values, i) for i in range(df.values.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Causation\n",
    "Granger's causality test is used to determine whether one time series influence another, i.e. it tests if there is causation or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "def causation_test(data: pd.DataFrame, verbose = False) -> bool:\n",
    "    maxlag = round(12 * pow(len(df) / 100, 1/4))\n",
    "    alpha = 0.05\n",
    "    results = pd.DataFrame([], columns = data.columns, index = data.columns)\n",
    "    causation = True\n",
    "\n",
    "    # TODO: find out whether we need to have causation between all variables,\n",
    "    #       or only for the variable we want, the rgdpna\n",
    "    for col in results.columns:\n",
    "        for row in results.index:\n",
    "            if row == col:\n",
    "                results.loc[row, col] = ''\n",
    "                continue\n",
    "\n",
    "            result = grangercausalitytests(\n",
    "                data[[row, col]],\n",
    "                maxlag   = maxlag,\n",
    "                addconst = True,\n",
    "                verbose  = False\n",
    "            )\n",
    "\n",
    "            p_values = [round(result[i + 1][0]['ssr_chi2test'][1], 3) for i in range(maxlag)]\n",
    "            p_value = np.min(p_values)\n",
    "\n",
    "            results.loc[row, col] = p_value\n",
    "\n",
    "            if p_value >= alpha:\n",
    "                causation = False\n",
    "\n",
    "    if verbose:\n",
    "        display(results)\n",
    "\n",
    "    return causation\n",
    "\n",
    "for country, df in countries.items():\n",
    "    display(Markdown(f'### {country}'))\n",
    "\n",
    "    if causation_test(df['raw'], True):\n",
    "        print('Causation is present between all variables')\n",
    "    else:\n",
    "        print('Causation is not present for all variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Cointegration\n",
    "Cointegration means there is a long-term tendency for two or more time series to move together.\n",
    "\n",
    "There are multiple ways to test for cointegration, like Engle-Granger and Johansen. While the Engle-Granger test is more simple, the Johansen test allows for multiple cointegrated relationships to be tested. Johansen is therefore the one that is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "def cointegration_test(data: pd.DataFrame, verbose = False) -> bool:\n",
    "    results = pd.DataFrame()\n",
    "    cointegration = True\n",
    "\n",
    "    result = coint_johansen(\n",
    "        data,\n",
    "        det_order = -1, # No deterministic terms\n",
    "        k_ar_diff = 5 # TODO not entirely sure what value we should use here\n",
    "    )\n",
    "\n",
    "    for name, trace, cv95 in zip(data.columns, result.trace_stat, result.cvt[:,1]):\n",
    "        results[name] = {\n",
    "            'Trace':                round(trace, 3),\n",
    "            'Critical Value (95%)': round(cv95, 3),\n",
    "            'Significant':          'Yes' if trace > cv95 else 'No'\n",
    "        }\n",
    "\n",
    "        if trace <= cv95:\n",
    "            cointegration = False\n",
    "    \n",
    "    if verbose:\n",
    "        display(results.transpose())\n",
    "\n",
    "    return cointegration\n",
    "\n",
    "for country, df in countries.items():\n",
    "    display(Markdown(f'### {country}'))\n",
    "\n",
    "    if cointegration_test(df['raw'], True):\n",
    "        print('A significant relationship is present between all variables')\n",
    "    else:\n",
    "        print('A significant relationship is not present for all variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "Now we split the data into a test, and training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in countries.items():\n",
    "    train_length = int(len(df['raw']) * 0.75)\n",
    "\n",
    "    countries[country]['train_length'] = train_length\n",
    "    countries[country]['train'] = df['raw'][:train_length]\n",
    "    countries[country]['test'] = df['raw'][train_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity\n",
    "Now a _Augmented Dickey-Fuller (ADF)_ test is performed to check if the data is stationary.\n",
    "\n",
    "When time series data is stationary, its properties such as variance and mean, are constant over time. For VAR to forecast meaningful results, it is required that the data that is put in is stationary. \n",
    "\n",
    "There are also other methods of determining whether a series is stationary or not, but ADF seems to be the most popular one.\n",
    "\n",
    "A significance level (alpha) of __5%__ is used to determine whether or not a series is stationary or not.\n",
    "\n",
    "If any series is not stationary, all series are differenced again until they all are stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def stationarity_test(data: pd.DataFrame, verbose = False) -> bool:\n",
    "    maxlag = round(12 * pow(len(df) / 100, 1/4))\n",
    "    alpha = 0.05\n",
    "    results = pd.DataFrame()\n",
    "    stationary = True\n",
    "\n",
    "    for name, series in data.items():\n",
    "        result = adfuller(\n",
    "            series,\n",
    "            maxlag     = maxlag,\n",
    "            regression = 'c', # Constant regression\n",
    "            autolag    = 'AIC', \n",
    "            store      = False,\n",
    "            regresults = False\n",
    "        )\n",
    "\n",
    "        results[name] = {\n",
    "            'P-Value':     round(result[1], 3),\n",
    "            'Number lags': result[2],\n",
    "            'Stationary':  'Yes' if result[1] <= alpha else 'No'\n",
    "        }\n",
    "\n",
    "        if result[1] > alpha:\n",
    "            stationary = False\n",
    "\n",
    "    if verbose:\n",
    "        display(results.transpose())\n",
    "\n",
    "    return stationary\n",
    "\n",
    "for country, df in countries.items():\n",
    "    display(Markdown(f'### {country}'))\n",
    "\n",
    "    countries[country]['diff'] = df['train'].copy()\n",
    "    countries[country]['diff_passes'] = 0\n",
    "\n",
    "    while stationarity_test(df['diff'], True) == False:\n",
    "        #if diff_pass >= 1:\n",
    "        #    #raise Exception('Whoops', 'Unable to make all series stationary')\n",
    "        #    break\n",
    "        countries[country]['diff_passes'] += 1\n",
    "\n",
    "        print(f'One or more series are non-stationary, differencing... (pass = {df[\"diff_passes\"]})')\n",
    "\n",
    "        countries[country]['diff'] = df['diff'].diff().dropna()\n",
    "\n",
    "        if df['diff_passes'] > 2:\n",
    "            raise Exception('Whoops', 'Unable to make all series stationary')\n",
    "            break\n",
    "    else:\n",
    "        print(f'All series are stationary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Lag Order Selection\n",
    "\n",
    "The lag order refers to how far the VAR model looks back in the time series.\n",
    "\n",
    "TODO pas aan\n",
    "Determining the optimal lag order will greatly influence the results of the prediction. Besides manually selecting the lag order, there are several statistical methods that select the lag order, such as AIC, BIC, FPE and HQIC.\n",
    "\n",
    "Here, the lag order is automatically chosen based on the HQIC method. QHIC is a combination of both AIC and BIC.\n",
    "AIC is the most simple method, but is prone to overfitting.\n",
    "BIC is more conservative, and is less likely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "from VARParameterSelection import VARParameterSelection\n",
    "\n",
    "for country, df in countries.items():\n",
    "    display(Markdown(f'### {country}'))\n",
    "\n",
    "    model = VAR(df['diff'], freq = df['diff'].index.inferred_freq)\n",
    "\n",
    "    params = VARParameterSelection.var_parameter_search(\n",
    "        model         = model,\n",
    "        target_column = dep,\n",
    "        df_train      = df['train'],\n",
    "        df_diff       = df['diff'],\n",
    "        df_test       = df['test'],\n",
    "    )\n",
    "\n",
    "    #countries[country]['maxlag'] = model.select_order().selected_orders['aic']\n",
    "    countries[country]['maxlag'] = params[0].lag\n",
    "    trend = params[0].trend\n",
    "\n",
    "    print(f'Best found maxlag = {df['maxlag']}')\n",
    "    print(f'Best found trend = {trend}')\n",
    "\n",
    "    countries[country]['results'] = model.fit(\n",
    "        maxlags = df['maxlag'],\n",
    "        method  = 'ols',\n",
    "        ic      = None,\n",
    "        trend   = trend\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Normality\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in countries.items():\n",
    "    display(Markdown(f'### {country}'))\n",
    "    print(df['results'].test_normality())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Serial Correlation of Residuals\n",
    "\n",
    "TODO explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "for country, df in countries.items():\n",
    "    display(Markdown(f'### {country}'))\n",
    "\n",
    "    out = durbin_watson(df['results'].resid)\n",
    "\n",
    "    for col, val in zip(df['raw'].columns, out):\n",
    "        print(str(col).ljust(10), ':', round(val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "Now the model will make a prediction for the period of the test data based on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_inv(forecast_diff, original, passes):\n",
    "    df_temp = forecast_diff.copy()\n",
    "\n",
    "    for i in range(passes, 0, -1):\n",
    "        df_orig = original.iloc[-1]\n",
    "\n",
    "        for j in range(2, i + 1):\n",
    "            df_orig = df_orig - original.iloc[-j]\n",
    "\n",
    "        df_temp = df_orig + df_temp.cumsum()\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "df_forecast = {}\n",
    "df_lower_error = {}\n",
    "df_upper_error = {}\n",
    "\n",
    "for country, df in countries.items():\n",
    "    horizon = len(df['test'])\n",
    "    alpha = 0.05\n",
    "\n",
    "    # Do the forecast\n",
    "    mid, lower, upper = df['results'].forecast_interval(df['diff'].values[-df['maxlag']:], steps = horizon, alpha = alpha)\n",
    "\n",
    "    # Put it into a dataframe\n",
    "    countries[country]['forecast'] = pd.DataFrame(mid, columns = df['diff'].columns, index = df['test'].iloc[:horizon].index)\n",
    "    countries[country]['lower_error'] = pd.DataFrame(lower, columns = df['diff'].columns, index = df['test'].iloc[:horizon].index)\n",
    "    countries[country]['upper_error'] = pd.DataFrame(upper, columns = df['diff'].columns, index = df['test'].iloc[:horizon].index)\n",
    "\n",
    "    # Reverse the differencing\n",
    "    if df['diff_passes'] > 0:\n",
    "        original = df['train']\n",
    "        passes = df['diff_passes']\n",
    "\n",
    "        countries[country]['forecast'] = diff_inv(df['forecast'], original, passes)\n",
    "        countries[country]['lower_error'] = diff_inv(df['lower_error'], original, passes)\n",
    "        countries[country]['upper_error'] = diff_inv(df['upper_error'], original, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import StandardScaler\n",
    "\n",
    "for country, df in countries.items():\n",
    "    rmse = mean_squared_error(df['forecast'][dep], df['test'][dep].values[:horizon], squared = False)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    ax.plot(df['train'][-train_length:][dep], color='black', label='Train')\n",
    "    ax.plot(df['test'][:horizon][dep], color='tab:blue', label = 'Test')\n",
    "    ax.plot(df['forecast'][dep], color = 'tab:orange', label = 'Forecast')\n",
    "\n",
    "    ylims = ax.get_ylim()\n",
    "    ax.fill_between(\n",
    "        df['forecast'][dep].index,\n",
    "        df['lower_error'][dep].values,\n",
    "        df['upper_error'][dep].values,\n",
    "        color = 'bisque',\n",
    "        label = f'{int(100 - (alpha * 100))}% CI'\n",
    "    )\n",
    "\n",
    "    ax.set_ylim(ylims)\n",
    "\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines['top'].set_alpha(0)\n",
    "    ax.tick_params(labelsize = 6)\n",
    "    ax.set_title(f'{country} {dep_name}')\n",
    "    ax.set_title(f'RMSE: {round(rmse, 3)}', loc = 'left', x = 0.04, y = 0.9, fontsize = 'small', color = 'white', backgroundcolor = 'gray')\n",
    "    ax.legend(loc = 'lower right')\n",
    "    ax.spines[['right', 'top']].set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
